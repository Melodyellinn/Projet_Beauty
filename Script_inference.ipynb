{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8da0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import sqlite3 as sql\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28287573",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect('Application_prod.db')\n",
    "data = pd.read_sql(\"\"\"SELECT * \n",
    "                      FROM Result_data\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a9c32ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-31 00:00:00\n",
      "2022-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data.date.max())\n",
    "print(data.date.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3144908",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/60cfa1a830df457eb19b304db7987927/model_xgboost'\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.xgboost.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c7efe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172326"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= data.copy().drop([\"country\",'medium','date',\"index\",\"bounces\"],axis=1).set_index('fullVisitorId')\n",
    "categorial = df[['channelGrouping','deviceCategory']]\n",
    "\n",
    "for i in categorial.columns:\n",
    "    df[i]= LabelEncoder().fit_transform(df[i])\n",
    "    df[i].unique()\n",
    "len(loaded_model.predict_proba(df)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b347078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_on_site</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>deviceCategory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1841398939845413817</th>\n",
       "      <td>11142</td>\n",
       "      <td>330.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841398939845413817</th>\n",
       "      <td>11142</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841398939845413817</th>\n",
       "      <td>11142</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841398939845413817</th>\n",
       "      <td>11142</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841398939845413817</th>\n",
       "      <td>11142</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188970518717118040</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292485821672248839</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539970384252655476</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896625306031106609</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208529202780866062</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Direct</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172326 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time_on_site  pageviews channelGrouping deviceCategory\n",
       "fullVisitorId                                                              \n",
       "1841398939845413817         11142      330.0          Direct        desktop\n",
       "1841398939845413817         11142       59.0          Direct        desktop\n",
       "1841398939845413817         11142       55.0          Direct        desktop\n",
       "1841398939845413817         11142      144.0          Direct        desktop\n",
       "1841398939845413817         11142       67.0          Direct        desktop\n",
       "...                           ...        ...             ...            ...\n",
       "9188970518717118040             0        1.0          Direct        desktop\n",
       "5292485821672248839             0        1.0          Direct        desktop\n",
       "5539970384252655476             0        1.0          Direct        desktop\n",
       "5896625306031106609             0        1.0          Direct        desktop\n",
       "9208529202780866062             0        1.0          Direct        desktop\n",
       "\n",
       "[172326 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59845e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "first Run of infering creating table\n"
     ]
    }
   ],
   "source": [
    "conn = sql.connect('Application_prod.db')\n",
    "\n",
    "data = pd.read_sql(\"\"\"SELECT * \n",
    "                      FROM Raw_data\"\"\", conn)\n",
    "\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "date = \"20221001\"\n",
    "#today_date  = datetime.today()\n",
    "\n",
    "today_date = datetime.strptime(date,\"%Y%m%d\")\n",
    "last_date = today_date - timedelta(days=7)\n",
    "#focus_data = data.copy()[data['date'].between(last_date,today_date)]\n",
    "focus_data= data.copy()\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "\n",
    "df = focus_data.set_index('fullVisitorId').drop([\"country\",'medium','date',\"index\",\"bounces\"],axis=1)\n",
    "#change categorial columns\n",
    "\n",
    "categorial = df[['channelGrouping','deviceCategory']]\n",
    "\n",
    "for i in categorial.columns:\n",
    "    df[i]= LabelEncoder().fit_transform(df[i])\n",
    "    df[i].unique()\n",
    "    \n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "\n",
    "logged_model = 'runs:/60cfa1a830df457eb19b304db7987927/model_xgboost'\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.xgboost.load_model(logged_model)\n",
    "# Predict on a Pandas DataFrame.\n",
    "result = loaded_model.predict(df)\n",
    "result_proba = loaded_model.predict_proba(df)[:,1]\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "\n",
    "data_result = focus_data.copy().dropna(axis=0)\n",
    "data_result['Predict'] = result\n",
    "data_result['Predict_proba']= result_proba\n",
    "\n",
    "result_to_save = data_result[[\"index\",\"fullVisitorId\",\"date\",\"Predict\",\"Predict_proba\"]]\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    check_date = pd.read_sql(\"SELECT * FROM Result_data\",conn)\n",
    "    print(\"Data existing wait to compare\")\n",
    "    \n",
    "    check_date[\"date\"] = pd.to_datetime(check_date[\"date\"])\n",
    "    if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]!= 0 :\n",
    "        print(\"Already Trained Data\")\n",
    "        if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]<(result_to_save.count()[0]*0.85):\n",
    "            pourcent_trained = round(check_date[check_date[\"date\"].between(last_date,today_date)].count()[0] / result_to_save.count()[0] * 100,2)\n",
    "            print(f\"Data partialy to append check duplicate afterward.\\n {pourcent_trained} % of the data already trained\")\n",
    "            result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n",
    "        else: \n",
    "            print(\"Data trained to more than 85% data dropped\")\n",
    "            \n",
    "    else:\n",
    "        print(\"New Fresh Run append\")\n",
    "        result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n",
    "        \n",
    "        \n",
    "except:\n",
    "    print(\"first Run of infering creating table\")\n",
    "    \n",
    "    result_to_save.to_sql(\"Result_data\",conn, if_exists =\"replace\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d79932",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3b10aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = focus_data.set_index('fullVisitorId')\n",
    "df = df.copy()[df[\"country\"].isin([\"United States\", \"France\", \n",
    "                                                \"India\", \"China\", \"Germany\",\n",
    "                                                \"Canada\", \"(not set)\"])]\n",
    "#change categorial columns\n",
    "categorial = df[['channelGrouping','deviceCategory', 'country']]\n",
    "\n",
    "for i in categorial.columns:\n",
    "    df[i]= LabelEncoder().fit_transform(df[i])\n",
    "    df[i].unique()\n",
    "    \n",
    "\n",
    "df = df.drop(['medium','date',\"index\"], axis= 1)\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f8db3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/1489eb854fb249f388e3404ab0b9fef4/model_xgboost'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "result = loaded_model.predict(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "604d9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result = focus_data.copy()[focus_data.country.isin([\"United States\", \"France\", \n",
    "                                                \"India\", \"China\", \"Germany\",\n",
    "                                                \"Canada\", \"(not set)\"])].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "29296a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result['Predict'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9f51887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_to_save = data_result[[\"index\",\"fullVisitorId\",\"date\",\"Predict\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "40a118d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data existing wait to compare\n",
      "Already Trained Data\n",
      "Data partialy to append check duplicate afterward.\n",
      " 42.8 % of the data already trained\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    check_date = pd.read_sql(\"SELECT * FROM Result_data\",conn)\n",
    "    print(\"Data existing wait to compare\")\n",
    "    \n",
    "    check_date[\"date\"] = pd.to_datetime(check_date[\"date\"])\n",
    "    if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]!= 0 :\n",
    "        print(\"Already Trained Data\")\n",
    "        if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]<(result_to_save.count()[0]*0.85):\n",
    "            pourcent_trained = round(check_date[check_date[\"date\"].between(last_date,today_date)].count()[0] / result_to_save.count()[0] * 100,2)\n",
    "            print(f\"Data partialy to append check duplicate afterward.\\n {pourcent_trained} % of the data already trained\")\n",
    "            result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n",
    "        else: \n",
    "            print(\"Data trained to more than 85% data dropped\")\n",
    "            \n",
    "    else:\n",
    "        print(\"New Fresh Run append\")\n",
    "        result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n",
    "        \n",
    "        \n",
    "except:\n",
    "    print(\"first Run of infering creating table\")\n",
    "    \n",
    "    result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89615d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Trained Data\n",
      "Data trained to more than 80% data dropped\n"
     ]
    }
   ],
   "source": [
    "check_date[\"date\"] = pd.to_datetime(check_date[\"date\"])\n",
    "if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]!= 0 :\n",
    "    print(\"Already Trained Data\")\n",
    "    if check_date[check_date[\"date\"].between(last_date,today_date)].count()[0]<(result_to_save.count()[0]*0.85):\n",
    "        print(\"Data partialy append check duplicate\")\n",
    "        #result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n",
    "    else: \n",
    "        print(\"Data trained to more than 80% data dropped\")\n",
    "\n",
    "else:\n",
    "    print(\"new_clean_run\")\n",
    "    #result_to_save.to_sql(\"Result_data\",conn, if_exists =\"append\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c54d331",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: Result_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11308\\3213892820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Doping EMPLOYEE table if already exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP TABLE Result_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Table dropped... \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: Result_data"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "#Connecting to sqlite\n",
    "conn = sql.connect('Application_prod.db')\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Doping EMPLOYEE table if already exists\n",
    "cursor.execute(\"DROP TABLE Result_data\")\n",
    "print(\"Table dropped... \")\n",
    "\n",
    "#Commit your changes in the database\n",
    "conn.commit()\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f36a6e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_date[check_date[\"date\"].between(last_date,today_date)].count()[0] !=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "41f7ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_date = pd.read_sql(\"SELECT * FROM Result_data\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84d3a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "year = str(20220919)[:4]\n",
    "month = str(20220919)[4:6]\n",
    "day = str(20220919)[6:]\n",
    "date = f\"{year}-{month}-{day}\"\n",
    "date_e = datetime.datetime.strptime(date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "694a4d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 9, 19, 0, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51fdb0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47014 entries, 0 to 48053\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   fullVisitorId    47014 non-null  uint64 \n",
      " 1   bounces          47014 non-null  int64  \n",
      " 2   time_on_site     47014 non-null  int64  \n",
      " 3   pageviews        47014 non-null  float64\n",
      " 4   medium           47014 non-null  object \n",
      " 5   channelGrouping  47014 non-null  object \n",
      " 6   deviceCategory   47014 non-null  object \n",
      " 7   country          47014 non-null  object \n",
      " 8   date             47014 non-null  int64  \n",
      " 9   Predict          47014 non-null  int32  \n",
      "dtypes: float64(1), int32(1), int64(3), object(4), uint64(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c542457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
